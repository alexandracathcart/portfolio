{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP and the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai-gvPnADykO",
    "toc-hr-collapsed": true
   },
   "source": [
    "In this project I apply NLP transforms to a collection of George Elliot texts to create dan F3 level digital analytical edition from them\n",
    "\n",
    "First, I import and combine the following three novels:\n",
    "* Middlemarch http://www.gutenberg.org/files/145/145-0.txt\n",
    "* The Mill on the Floss http://www.gutenberg.org/files/6688/6688-0.txt\n",
    "* Adam Bede http://www.gutenberg.org/files/507/507-0.txt\n",
    "\n",
    "Then, I produce the following tables as data frames and save them as CSV tables:\n",
    "* A library table (LIBRARY) with basic metadata about each book.\n",
    "* A document table (DOC) with the preserved paragraphs of each book and an appropriate OHCO index.\n",
    "* A token table (TOKEN) with an appropriate OHCO index including part-of-speech tags derived from NLTK.\n",
    "* A vocabulary (VOCAB) table of terms with stopwords and porter stems annotations derived from NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "epub_dir = 'texts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "Q4Id4bNP5t4p",
    "outputId": "1be778b1-a6a6-45e5-8773-010e83904be3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alexcathcart/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alexcathcart/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexcathcart/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/alexcathcart/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect\n",
    "\n",
    "Since Project Gutenberg texts vary widely in their markup, I define the chunking patterns by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "chap_pats = {\n",
    "    145: {\n",
    "        'start_line': 206,\n",
    "        'end_line': 33304,\n",
    "        'volume': re.compile('^\\s*BOOK\\s+{}\\.\\s*$'.format(roman)),\n",
    "        'chapter': re.compile('^\\s*CHAPTER\\s+{}\\.\\s*$'.format(roman))\n",
    "    },\n",
    "    507: {\n",
    "        'start_line': 39,\n",
    "        'end_line': 20409,\n",
    "        'volume': re.compile('^\\s*Book\\s+{}\\.\\s*$'),\n",
    "        'chapter': re.compile('^\\s*Chapter\\s+{}\\s*$'.format(roman))\n",
    "    },\n",
    "    6688: {\n",
    "        'start_line': 124,\n",
    "        'end_line': 21265,\n",
    "        'volume': re.compile('^\\s*BOOK\\s+{}\\.\\s*$'),\n",
    "        'chapter': re.compile('^\\s*Chapter\\s+{}\\.\\s*$'.format(roman))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register and Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epubs = [epub for epub in sorted(glob(epub_dir+'/*.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_epubs(epub_list, chap_pats, OHCO=OHCO):\n",
    "    \n",
    "    my_lib = []\n",
    "    my_doc = []\n",
    "\n",
    "    for epub_file in epubs:\n",
    "        \n",
    "        # Get PG ID from filename\n",
    "        book_id = int(epub_file.split('-')[-1].split('.')[0].replace('pg',''))\n",
    "        print(\"BOOK ID\", book_id)\n",
    "        \n",
    "        # Import file as lines\n",
    "        lines = open(epub_file, 'r', encoding='utf-8-sig').readlines()\n",
    "        df = pd.DataFrame(lines, columns=['line_str'])\n",
    "        df.index.name = 'line_num'\n",
    "        df.line_str = df.line_str.str.strip()\n",
    "        df['book_id'] = book_id\n",
    "    \n",
    "      \n",
    "        # FIX CHARACTERS TO IMPROVE TOKENIZATION\n",
    "        df.line_str = df.line_str.str.replace('—', ' — ')\n",
    "        df.line_str = df.line_str.str.replace('-', ' - ')\n",
    "        \n",
    "        # Get book title and put into LIB table -- note problems, though\n",
    "        book_title = re.sub(r\"The Project Gutenberg eBook( of|,) \", \"\", df.loc[0].line_str, flags=re.IGNORECASE)\n",
    "        book_title = re.sub(r\"Project Gutenberg's \", \"\", book_title, flags=re.IGNORECASE)\n",
    "\n",
    "        # Remove cruft\n",
    "        a = chap_pats[book_id]['start_line'] - 1\n",
    "        b = chap_pats[book_id]['end_line'] + 1\n",
    "        df = df.iloc[a:b]\n",
    "        \n",
    "        # Chunk by chapter\n",
    "        chap_lines = df.line_str.str.match(chap_pats[book_id]['chapter'])\n",
    "        chap_nums = [i+1 for i in range(df.loc[chap_lines].shape[0])]\n",
    "        df.loc[chap_lines, 'chap_num'] = chap_nums\n",
    "        df.chap_num = df.chap_num.ffill()\n",
    "    \n",
    "        # Clean up\n",
    "        df = df[~df.chap_num.isna()] # Remove chapter heading lines\n",
    "        df = df.loc[~chap_lines] # Remove everything before Chapter 1\n",
    "        df['chap_num'] = df['chap_num'].astype('int')\n",
    "           \n",
    "        # Group -- Note that we exclude the book level in the OHCO at this point\n",
    "        df = df.groupby(OHCO[1:2]).line_str.apply(lambda x: '\\n'.join(x)).to_frame() # Make big string\n",
    "        \n",
    "        # Split into paragrpahs\n",
    "        df = df['line_str'].str.split(r'\\n\\n+', expand=True).stack().to_frame().rename(columns={0:'para_str'})\n",
    "        df.index.names = OHCO[1:3] # MAY NOT BE NECESSARY UNTIL THE END\n",
    "        df['para_str'] = df['para_str'].str.replace(r'\\n', ' ').str.strip()\n",
    "        df = df[~df['para_str'].str.match(r'^\\s*$')] # Remove empty paragraphs\n",
    "        \n",
    "        # Set index\n",
    "        df['book_id'] = book_id\n",
    "        df = df.reset_index().set_index(OHCO[:3])\n",
    "    \n",
    "        # Register\n",
    "        my_lib.append((book_id, book_title, epub_file))\n",
    "        my_doc.append(df)\n",
    "    \n",
    "\n",
    "    docs = pd.concat(my_doc)\n",
    "    library = pd.DataFrame(my_lib, columns=['book_id', 'book_title', 'book_file']).set_index('book_id')\n",
    "    print(\"Done.\")\n",
    "    return library, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK ID 145\n",
      "BOOK ID 507\n",
      "BOOK ID 6688\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "epubs = [epub for epub in sorted(glob(epub_dir+'/*.txt'))]\n",
    "LIB, DOC = acquire_epubs(epubs, chap_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Middlemarch, by George Eliot</td>\n",
       "      <td>texts/-pg145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Adam Bede, by George Eliot</td>\n",
       "      <td>texts/-pg507.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>The Mill on the Floss, by George Eliot</td>\n",
       "      <td>texts/-pg6688.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     book_title          book_file\n",
       "book_id                                                           \n",
       "145                Middlemarch, by George Eliot   texts/-pg145.txt\n",
       "507                  Adam Bede, by George Eliot   texts/-pg507.txt\n",
       "6688     The Mill on the Floss, by George Eliot  texts/-pg6688.txt"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <th>44</th>\n",
       "      <th>5</th>\n",
       "      <td>“Let me see, — it’s going on for seven years n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>65</th>\n",
       "      <th>23</th>\n",
       "      <td>“I have only wished to prevent you from hurryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">507</th>\n",
       "      <th>12</th>\n",
       "      <th>48</th>\n",
       "      <td>But they started asunder with beating hearts: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>36</th>\n",
       "      <td>“Nay, my lad, nay,” Lisbeth burst out in an ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">145</th>\n",
       "      <th>12</th>\n",
       "      <th>152</th>\n",
       "      <td>“At least, Fred, let me advise _you_ not to fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <th>30</th>\n",
       "      <td>At this crisis Lydgate was announced, and one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <th>48</th>\n",
       "      <th>59</th>\n",
       "      <td>“Yes, Lucy, I would choose to marry him. I thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <th>53</th>\n",
       "      <th>55</th>\n",
       "      <td>“Aye, aye!” said Bartle; “then we can have a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <th>29</th>\n",
       "      <th>34</th>\n",
       "      <td>“What am I to write?” said Tom, with gloomy su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>12</th>\n",
       "      <th>85</th>\n",
       "      <td>“There is no question of liking at present. My...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    para_str\n",
       "book_id chap_num para_num                                                   \n",
       "6688    44       5         “Let me see, — it’s going on for seven years n...\n",
       "145     65       23        “I have only wished to prevent you from hurryi...\n",
       "507     12       48        But they started asunder with beating hearts: ...\n",
       "        11       36        “Nay, my lad, nay,” Lisbeth burst out in an ea...\n",
       "145     12       152       “At least, Fred, let me advise _you_ not to fa...\n",
       "        50       30        At this crisis Lydgate was announced, and one ...\n",
       "6688    48       59        “Yes, Lucy, I would choose to marry him. I thi...\n",
       "507     53       55        “Aye, aye!” said Bartle; “then we can have a b...\n",
       "6688    29       34        “What am I to write?” said Tom, with gloomy su...\n",
       "145     12       85        “There is no question of liking at present. My..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and Annotate\n",
    "\n",
    "Using NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.para_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x))) # Discards stuff in between\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.7 s, sys: 1.19 s, total: 50.9 s\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TOKEN = tokenize(DOC, ws=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">145</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Since, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>Since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(I, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(can, MD)</td>\n",
       "      <td>MD</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(do, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(no, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pos_tuple  pos token_str\n",
       "book_id chap_num para_num sent_num token_num                            \n",
       "145     1        0        0        0          (Since, IN)   IN     Since\n",
       "                                   1             (I, PRP)  PRP         I\n",
       "                                   2            (can, MD)   MD       can\n",
       "                                   3             (do, VB)   VB        do\n",
       "                                   4             (no, DT)   DT        no"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">145</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>10</th>\n",
       "      <td>(Reach, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Reach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>2</th>\n",
       "      <td>(Maid, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Maid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(’, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(BEAUMONT, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>BEAUMONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(AND, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>AND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6688</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">58</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">67</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>9</th>\n",
       "      <td>(Red, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Deeps, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Deeps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">68</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>6</th>\n",
       "      <td>(Tom, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Maggie, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Maggie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Tulliver, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Tulliver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48776 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    pos_tuple  pos token_str\n",
       "book_id chap_num para_num sent_num token_num                                \n",
       "145     1        0        0        10            (Reach, NNP)  NNP     Reach\n",
       "                          1        2              (Maid, NNP)  NNP      Maid\n",
       "                                   3                 (’, NNP)  NNP         ’\n",
       "                                   8          (BEAUMONT, NNP)  NNP  BEAUMONT\n",
       "                                   9               (AND, NNP)  NNP       AND\n",
       "...                                                       ...  ...       ...\n",
       "6688    58       67       1        9               (Red, NNP)  NNP       Red\n",
       "                                   10            (Deeps, NNP)  NNP     Deeps\n",
       "                 68       0        6               (Tom, NNP)  NNP       Tom\n",
       "                                   8            (Maggie, NNP)  NNP    Maggie\n",
       "                                   9          (Tulliver, NNP)  NNP  Tulliver\n",
       "\n",
       "[48776 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN[TOKEN.pos.str.match('^NNP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Reduce\n",
    "\n",
    "Extract a vocabulary from the TOKEN table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TOKEN.term_str.value_counts().to_frame()\\\n",
    "    .rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "3iYsuby6FYYR",
    "outputId": "b29dd1cd-a82a-44be-e21c-aa9b7e1e4933"
   },
   "outputs": [],
   "source": [
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "3iYsuby6FYYR",
    "outputId": "b29dd1cd-a82a-44be-e21c-aa9b7e1e4933"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>141032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1799</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1801</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str       n  num\n",
       "term_id                      \n",
       "0                 141032    0\n",
       "1              1       1    1\n",
       "2           1790       1    1\n",
       "3           1799       2    1\n",
       "4           1801       1    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDSH9L2TXGzH",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Annotate (VOCAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "US7EfWK_06FS"
   },
   "source": [
    "## Add Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDCfFuN80_rX"
   },
   "source": [
    "Using NLTK's built in stopword list for English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RG-5qYDR1YC2"
   },
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1925
    },
    "colab_type": "code",
    "id": "8vtGY9V82scz",
    "outputId": "e7ef30c7-3a05-4acf-e2cc-9154f589bd91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>should</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>there</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>having</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>above</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dummy\n",
       "term_str       \n",
       "any           1\n",
       "should        1\n",
       "there         1\n",
       "its           1\n",
       "as            1\n",
       "were          1\n",
       "most          1\n",
       "having        1\n",
       "above         1\n",
       "this          1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVJUOP9l2AS7"
   },
   "outputs": [],
   "source": [
    "VOCAB['stop'] = VOCAB.term_str.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "QXcA9xyY4JF_",
    "outputId": "340d1dab-1901-4eeb-b9d8-a269eba90dea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8935</th>\n",
       "      <td>himself</td>\n",
       "      <td>1079</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5576</th>\n",
       "      <td>doesn</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>between</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>them</td>\n",
       "      <td>1475</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>all</td>\n",
       "      <td>2666</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8664</th>\n",
       "      <td>hasn</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12760</th>\n",
       "      <td>off</td>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12193</th>\n",
       "      <td>mustn</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>couldn</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21506</th>\n",
       "      <td>yourself</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_str     n  num  stop\n",
       "term_id                           \n",
       "8935      himself  1079    0     1\n",
       "5576        doesn    62    0     1\n",
       "1793      between   374    0     1\n",
       "18902        them  1475    0     1\n",
       "522           all  2666    0     1\n",
       "8664         hasn    17    0     1\n",
       "12760         off   566    0     1\n",
       "12193       mustn    19    0     1\n",
       "4150       couldn    89    0     1\n",
       "21506    yourself   158    0     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDSH9L2TXGzH"
   },
   "source": [
    "## Add Stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE_YGklKXSYn"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.term_str.apply(stemmer1.stem)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "VOCAB['stem_snowball'] = VOCAB.term_str.apply(stemmer2.stem)\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "VOCAB['stem_lancaster'] = VOCAB.term_str.apply(stemmer3.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "dY__Bq0yXqbj",
    "outputId": "eddcdafe-e378-4f7b-ac6b-1fc41ef64fbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>council</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>council</td>\n",
       "      <td>council</td>\n",
       "      <td>council</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7369</th>\n",
       "      <td>flock</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>flock</td>\n",
       "      <td>flock</td>\n",
       "      <td>flock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>accent</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accent</td>\n",
       "      <td>accent</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11852</th>\n",
       "      <td>miser</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>miser</td>\n",
       "      <td>miser</td>\n",
       "      <td>mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>insignificant</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>insignific</td>\n",
       "      <td>insignific</td>\n",
       "      <td>insign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18179</th>\n",
       "      <td>stupendous</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>stupend</td>\n",
       "      <td>stupend</td>\n",
       "      <td>stupend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681</th>\n",
       "      <td>hatchin</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hatchin</td>\n",
       "      <td>hatchin</td>\n",
       "      <td>hatchin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15351</th>\n",
       "      <td>regulated</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>regul</td>\n",
       "      <td>regul</td>\n",
       "      <td>reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17385</th>\n",
       "      <td>soiling</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>soil</td>\n",
       "      <td>soil</td>\n",
       "      <td>soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19122</th>\n",
       "      <td>tightly</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tightli</td>\n",
       "      <td>tight</td>\n",
       "      <td>tight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term_str   n  num  stop stem_porter stem_snowball stem_lancaster\n",
       "term_id                                                                       \n",
       "4154           council   2    0     0     council       council        council\n",
       "7369             flock   7    0     0       flock         flock          flock\n",
       "105             accent  15    0     0      accent        accent            acc\n",
       "11852            miser   1    0     0       miser         miser            mis\n",
       "9874     insignificant  16    0     0  insignific    insignific         insign\n",
       "18179       stupendous   5    0     0     stupend       stupend        stupend\n",
       "8681           hatchin   1    0     0     hatchin       hatchin        hatchin\n",
       "15351        regulated   1    0     0       regul         regul            reg\n",
       "17385          soiling   1    0     0        soil          soil           soil\n",
       "19122          tightly   7    0     0     tightli         tight          tight"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "dY__Bq0yXqbj",
    "outputId": "eddcdafe-e378-4f7b-ac6b-1fc41ef64fbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>abjectly</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abjectli</td>\n",
       "      <td>abject</td>\n",
       "      <td>abject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>abruptly</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abruptli</td>\n",
       "      <td>abrupt</td>\n",
       "      <td>abrupt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>abstractedly</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abstractedli</td>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>abundantly</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abundantli</td>\n",
       "      <td>abund</td>\n",
       "      <td>abund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>accordingly</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accordingli</td>\n",
       "      <td>accord</td>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>yearly</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yearli</td>\n",
       "      <td>year</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21464</th>\n",
       "      <td>yearningly</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yearningli</td>\n",
       "      <td>yearn</td>\n",
       "      <td>yearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>yes</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ye</td>\n",
       "      <td>yes</td>\n",
       "      <td>ye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21518</th>\n",
       "      <td>zealous</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zealou</td>\n",
       "      <td>zealous</td>\n",
       "      <td>zeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21541</th>\n",
       "      <td>œdipus</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>œdipu</td>\n",
       "      <td>œdipus</td>\n",
       "      <td>œdip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             term_str    n  num  stop   stem_porter stem_snowball  \\\n",
       "term_id                                                             \n",
       "50           abjectly    1    0     0      abjectli        abject   \n",
       "64           abruptly   16    0     0      abruptli        abrupt   \n",
       "89       abstractedly    3    0     0  abstractedli      abstract   \n",
       "98         abundantly    4    0     0    abundantli         abund   \n",
       "142       accordingly   11    0     0   accordingli        accord   \n",
       "...               ...  ...  ...   ...           ...           ...   \n",
       "21460          yearly   10    0     0        yearli          year   \n",
       "21464      yearningly    1    0     0    yearningli         yearn   \n",
       "21476             yes  453    0     0            ye           yes   \n",
       "21518         zealous   10    0     0        zealou       zealous   \n",
       "21541          œdipus    2    0     0         œdipu        œdipus   \n",
       "\n",
       "        stem_lancaster  \n",
       "term_id                 \n",
       "50              abject  \n",
       "64              abrupt  \n",
       "89            abstract  \n",
       "98               abund  \n",
       "142             accord  \n",
       "...                ...  \n",
       "21460             year  \n",
       "21464            yearn  \n",
       "21476               ye  \n",
       "21518             zeal  \n",
       "21541             œdip  \n",
       "\n",
       "[570 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[VOCAB.stem_porter != VOCAB.stem_snowball]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC.to_csv('DOC.csv')\n",
    "LIB.to_csv('LIB.csv')\n",
    "VOCAB.to_csv('VOCAB.csv')\n",
    "TOKEN.to_csv('TOKEN.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_Annotations.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
