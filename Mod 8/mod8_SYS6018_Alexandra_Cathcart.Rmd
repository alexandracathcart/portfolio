---
title: "Alexandra Cathcart"
author: "mod7_SYS6018_Alexandra_Cathcart"
output:
  html_document:
    df_print: paged
---

***  
# Module 8 - Chapter 8 - 8.4 Exercises {.tabset}

## Problem # 7
### **In the lab, we applied random forests to the Boston data using mtry=6 and using ntree=25 and ntree=500. Create a plot displaying the test error resulting from random forests on this data set for a more comprehensive range of values for mtry and ntree. You can model your plot after Figure 8.10. Describe the results obtained.**  

```{r message=FALSE}
library(tree)
library(randomForest)
library(MASS)
library(ISLR)
library(gbm)
library(class)
```

```{r warning=FALSE}
#Create a plot displaying the test error resulting from random forests on this data set for a more comprehensive range of values for mtry and ntree.

#Split test/train 
set.seed(1)
subset<-sample(1:nrow(Boston),nrow(Boston)/2)
Boston.train<-Boston[subset,-14]
Boston.test<-Boston[-subset,-14]
y.train<-Boston[subset,14]
y.test<-Boston[-subset,14]
#Assign 7 models, three matching those in figure 8.10, four that build onto that set
rf.mod1<-randomForest(Boston.train,y.train,Boston.test,y.test,ntree=500,mtry=ncol(Boston.train))
rf.mod2<-randomForest(Boston.train,y.train,Boston.test,y.test,ntree=500,mtry=(ncol(Boston.train))/2)
rf.mod3<-randomForest(Boston.train,y.train,Boston.test,y.test,ntree=500,mtry=(ncol(Boston.train))/3)
rf.mod4<-randomForest(Boston.train,y.train,Boston.test,y.test,ntree=500,mtry=(ncol(Boston.train))/4)
rf.mod5<-randomForest(Boston.train,y.train,Boston.test,y.test,ntree=500,mtry=(ncol(Boston.train))/5)
rf.mod6<-randomForest(Boston.train,y.train,Boston.test,y.test,ntree=500,mtry=(ncol(Boston.train))/6)
rf.mod7<-randomForest(Boston.train,y.train,Boston.test,y.test,ntree=500,mtry=(ncol(Boston.train))^(0.5))
#Assign 5 models 
plot(1:500,rf.mod1$test$mse,col="black",type="l",xlab = "Number of Trees",ylab = "Test MSE",ylim = c(15,35))
lines(1:500,rf.mod2$test$mse, col="blue",type="l")
lines(1:500,rf.mod3$test$mse, col="green",type="l")
lines(1:500,rf.mod4$test$mse, col="purple",type="l")
lines(1:500,rf.mod5$test$mse, col="pink",type="l")
lines(1:500,rf.mod6$test$mse, col="red",type="l")
lines(1:500,rf.mod7$test$mse, col="orange",type="l")
legend("topright",c("m=p","m=p/2","m=p/3","m=p/4","m=p/5","m=p/6","m=sqrt(p)"),col=c("black","blue","green","purple","pink","red","orange"),cex=1,lty=1)
``` 

* Describe the results obtained:  
  + <span style="color: blue;">As ntree increases, the MSE decreases and then levels off. Similarly, as mtry gets smaller, the overall MSE measurement gets lower, until models 5 & 6 where we stop seeing improvement. The lowest MSE of all models is achieved with m=sqrt(p) and ~50-75 trees.</span>

***

## Problem # 8
### **In the lab, a classification tree was applied to the Carseats data set after converting Sales into a qualitative response variable. Now we will seek to predict Sales using regression trees and related approaches, treating the response as a quantitative variable.**  

**(a) Split the data set into a training set and a test set. **  

```{r warning=FALSE}
#Split the data set into a training set and a test set
set.seed(1)
subset<-sample(nrow(Carseats),nrow(Carseats)*0.7)
carseats.train<-Carseats[subset,]
carseats.test<-Carseats[-subset,]
``` 

**(b) Fit a regression tree to the training set. Plot the tree, and interpret the results. What test MSE do you obtain? **  

```{r message=FALSE}
#Fit a regression tree to the training set
carseats.tree <- tree(Sales ~ .,carseats.train)
#Plot the tree
plot(carseats.tree)
text(carseats.tree)
#Obtain MSE
carseats.tree.pred<-predict(carseats.tree,carseats.test)
(carseats.tree.mse<-mean((carseats.test$Sales-carseats.tree.pred)^2))
``` 

* What test MSE do you obtain?:  
  + <span style="color: blue;"> Test MSE: 4.208383. </span>

**(c) Use cross-validation in order to determine the optimal level of tree complexity. Does pruning the tree improve the test MSE? **  

```{r warning=FALSE}
#Use cross-validation  to determine the optimal level of tree complexity.
carseats.cv<-cv.tree(carseats.tree, FUN = prune.tree)
plot(carseats.cv$size,carseats.cv$dev,xlab = "Size of Tree",ylab = "Deviance",type = "b")
#Prune the tree according to the optimal tree complexity
carseats.tree.prune<-prune.tree(carseats.tree,best=8)
plot(carseats.tree.prune)
text(carseats.tree.prune)
#Calculate new MSE
carseats.pruned.pred<-predict(carseats.tree.prune,carseats.test)
(carseats.pruned.mse<-mean((carseats.pruned.pred-carseats.test$Sales)^2))
``` 

* Does pruning the tree improve the test MSE?:  
  + <span style="color: blue;"> No, pruning the tree does not improve the test MSE. The test MSE obtained from the pruned tree is 4.579256, compared to the full tree test MSE of 4.208383. </span>

**(d) Use the bagging approach in order to analyze this data. What test MSE do you obtain? Use the importance() function to determine which variables are most important. **  

```{r message=FALSE}
#Use the bagging approach in order to analyze this data.
carseats.bag <- randomForest(Sales ~ .,carseats.train,mtry = 10,ntree = 500,importance = TRUE)
carseats.bag.pred <- predict(carseats.bag,carseats.test)
(carseats.bag.mse <- mean((carseats.bag.pred - carseats.test$Sales)^2))
#Use the importance() function to determine which variables are most important.
importance(carseats.bag)
``` 

* What test MSE do you obtain? Which variables are most important? :  
  + <span style="color: blue;"> Test MSE: 2.56892. Most important variables: Price and ShelveLoc. </span>

**(e) Use random forests to analyze this data. What test MSE do you obtain? Use the importance() function to determine which variables are most important. Describe the effect of m, the number of variables considered at each split, on the error rate obtained. **  

```{r warning=FALSE}
p <- ncol(Carseats) - 1
#Use random forests to analyze this data. mtry = sqrt(p)
carseats.randf1 <- randomForest(Sales ~ .,carseats.train,mtry = sqrt(p),ntree = 500,importance = TRUE)
carseats.randf.pred1 <- predict(carseats.randf1,carseats.test)
(carseats.randf.mse1 <- mean((carseats.test$Sales - carseats.randf.pred1)^2))
#Use the importance() function to determine which variables are most important.
importance(carseats.randf1)

#-------

#Use random forests to analyze this data. mtry = p/3
carseats.randf2 <- randomForest(Sales ~ .,carseats.train,mtry = p/3,ntree = 500,importance = TRUE)
carseats.randf.pred2 <- predict(carseats.randf2,carseats.test)
(carseats.randf.mse2 <- mean((carseats.test$Sales - carseats.randf.pred2)^2))
#Use the importance() function to determine which variables are most important.
importance(carseats.randf2)

#-------

#Use random forests to analyze this data. mtry = 5
carseats.randf3 <- randomForest(Sales ~ .,carseats.train,mtry = 5,ntree = 500,importance = TRUE)
carseats.randf.pred3 <- predict(carseats.randf3,carseats.test)
(carseats.randf.mse3 <- mean((carseats.test$Sales - carseats.randf.pred3)^2))
#Use the importance() function to determine which variables are most important.
importance(carseats.randf3)

#-------

#Use random forests to analyze this data. mtry = p
carseats.randf4 <- randomForest(Sales ~ .,carseats.train,mtry = p,ntree = 500,importance = TRUE)
carseats.randf.pred4 <- predict(carseats.randf4,carseats.test)
(carseats.randf.mse4 <- mean((carseats.test$Sales - carseats.randf.pred4)^2))
#Use the importance() function to determine which variables are most important.
importance(carseats.randf4)
``` 

* What test MSE do you obtain? What effect does m have on the error rate? :  
  + <span style="color: blue;"> Test MSE: 2.905392. Most important variables are still Price and ShelveLoc. It appears that overall as m increases, the test mse decreases. </span>
  
***

## Problem # 11
### **This question uses the Caravan data set**  

**(a) Create a training set consisting of the first 1,000 observations, and a test set consisting of the remaining observations. **  

```{r warning=FALSE}
#Create a training set consisting of the first 1,000 observations, and a test set consisting of the remaining observations.
set.seed(1)
subset2<-1:1000
Caravan$Purchase<-ifelse(Caravan$Purchase=="Yes",1,0)
caravan.train<-Caravan[subset2,]
caravan.test<-Caravan[-subset2,]
``` 

**(b) Fit a boosting model to the training set with Purchase as the response and the other variables as predictors. Use 1,000 trees,and a shrinkage value of 0.01. Which predictors appear to be the most important? **  

```{r warning=FALSE}
#Fit a boosting model to the training set with Purchase as the response and the other variables as predictors. Use 1,000 trees,and a shrinkage value of 0.01.
caravan.boost <- gbm(Purchase ~ .,caravan.train,n.trees = 1000,shrinkage = 0.01,distribution = "bernoulli")
summary(caravan.boost)
``` 

* Which predictors appear to be the most important?:  
  + <span style="color: blue;"> PPERSAUT and MKOOPKLA. </span>

**(c) Use the boosting model to predict the response on the test data. Predict that a person will make a purchase if the estimated probability of purchase is greater than 20 %. Form a confusion matrix. What fraction of the people predicted to make a purchase do in fact make one? How does this compare with the results obtained from applying KNN or logistic regression to this data set? **  

```{r message=FALSE}
#Use the boosting model to predict the response on the test data. Predict that a person will make a purchase if the estimated probability of purchase is greater than 20 %.
caravan.boost.pred<-predict(caravan.boost,caravan.test,n.trees = 1000,type="response")
caravan.boost.prob<-ifelse(caravan.boost.pred>0.2,1,0)
#Form a confusion matrix.
table(caravan.test$Purchase,caravan.boost.prob,dnn=c("Actual","Predicted"))
#What fraction of the people predicted to make a purchase do in fact make one?
(purchaseMade<-30/(115+30))
``` 

* What fraction of the people predicted to make a purchase do in fact make one? :  
  + <span style="color: blue;"> ~20.7% </span> 

```{r warning=FALSE}
#GLM
caravan.glm<-glm(Purchase~.,caravan.train,family = "binomial")
#predict the response on the test data
carvan.glm.pred<-predict(caravan.glm,caravan.test,type="response")
caravan.glm.prob<-ifelse(carvan.glm.pred>0.2,1,0)
#Form a confusion matrix.
table(caravan.test$Purchase,caravan.glm.prob,dnn=c("Actual","Predicted"))
#What fraction of the people predicted to make a purchase do in fact make one?
(purchaseMadeGLM<-58/(350+58))
``` 

* How does [the purchaseMade fraction above] compare with the results obtained from applying KNN or logistic regression to this data set?:  
  + <span style="color: blue;"> According to the GLM model, only ~14.2% of of the people predicted to make a purchase do in fact make one. Therefore it would be recommended to use the boost model here, which produced a larger number of actual purchases in relation to predictions.</span>  